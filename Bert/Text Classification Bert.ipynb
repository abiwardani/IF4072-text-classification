{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZX8t/X8tx+JCmt/OceHrN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"71673315a4b749149fe537b05e0a8839":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_175cad295c484795aad2e0a6a5906ef3","IPY_MODEL_47fcf7dec6734c2bb3aea6df85aad94b","IPY_MODEL_a249d2100f5947adab4279ef94e28484"],"layout":"IPY_MODEL_3f8cc1ead55f4485b8be2655477a53c4"}},"175cad295c484795aad2e0a6a5906ef3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6f5d4e745b34a658886574f362e7fb2","placeholder":"​","style":"IPY_MODEL_d0d5c34fdd6345069401590a4bea0d82","value":""}},"47fcf7dec6734c2bb3aea6df85aad94b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_74b1e23c6e374798bf64aaeb68fc0980","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6a0bd9eba7e4b7589f31888c67f8eb7","value":0}},"a249d2100f5947adab4279ef94e28484":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0f76e1e1778461cb2e19b39a62da2fd","placeholder":"​","style":"IPY_MODEL_317d619f824a4408ba1bf0fa8914639f","value":" 0/0 [00:00&lt;?, ?it/s]"}},"3f8cc1ead55f4485b8be2655477a53c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f5d4e745b34a658886574f362e7fb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0d5c34fdd6345069401590a4bea0d82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74b1e23c6e374798bf64aaeb68fc0980":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e6a0bd9eba7e4b7589f31888c67f8eb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0f76e1e1778461cb2e19b39a62da2fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"317d619f824a4408ba1bf0fa8914639f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8d1788d398042ea9e9e9c83341f263d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db7471052cbd42d3b056a02274f2ff39","IPY_MODEL_5023b1054cd7422e9ed0f46b21df8832","IPY_MODEL_abf241d1e42a4a6ca16a4abec11de695"],"layout":"IPY_MODEL_4f2c7d5c6fcf42cd9762cac96d1ac088"}},"db7471052cbd42d3b056a02274f2ff39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d277e49a84674c5ab627f77048171a6c","placeholder":"​","style":"IPY_MODEL_1b0a988422ed4bcf82b25861f6a5911b","value":"Downloading: 100%"}},"5023b1054cd7422e9ed0f46b21df8832":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffc38f6570434896bc06e2dbc5ed4fa7","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3273a302face491dba88152561c1f080","value":995526}},"abf241d1e42a4a6ca16a4abec11de695":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91e101f1a40d48fd9914b8168f97f85e","placeholder":"​","style":"IPY_MODEL_b21d663a82e74a7492fd444911f7554f","value":" 996k/996k [00:00&lt;00:00, 3.07MB/s]"}},"4f2c7d5c6fcf42cd9762cac96d1ac088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d277e49a84674c5ab627f77048171a6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b0a988422ed4bcf82b25861f6a5911b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffc38f6570434896bc06e2dbc5ed4fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3273a302face491dba88152561c1f080":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91e101f1a40d48fd9914b8168f97f85e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b21d663a82e74a7492fd444911f7554f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c1555562b7e4f7ea2dff9ebe39950a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e7d5fb14f7f472b9cdf8f44fc614b92","IPY_MODEL_786a87661882429f847da3b53c4e9f89","IPY_MODEL_2a695cefd0e44a71b3bed2ecb51caf20"],"layout":"IPY_MODEL_8ac8e873d1224b27ab6d45cb0965a593"}},"8e7d5fb14f7f472b9cdf8f44fc614b92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68a542ae389441f19c9ab1343cde6c4d","placeholder":"​","style":"IPY_MODEL_ed79622d30b440aa9df6f8acca2e303f","value":"Downloading: 100%"}},"786a87661882429f847da3b53c4e9f89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8f04f1894604124aa855ecee2403604","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ed7d2a331d44fb2a73934e76a90c5c1","value":29}},"2a695cefd0e44a71b3bed2ecb51caf20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2714361b6e34d9f99973a545a22c116","placeholder":"​","style":"IPY_MODEL_ece7a32729e444528b4be7046ceec901","value":" 29.0/29.0 [00:00&lt;00:00, 858B/s]"}},"8ac8e873d1224b27ab6d45cb0965a593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68a542ae389441f19c9ab1343cde6c4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed79622d30b440aa9df6f8acca2e303f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8f04f1894604124aa855ecee2403604":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ed7d2a331d44fb2a73934e76a90c5c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2714361b6e34d9f99973a545a22c116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ece7a32729e444528b4be7046ceec901":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7baf9992cd64b92b0e210ef949139fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce669861c7864894a944eed1bcc99e30","IPY_MODEL_34fec00797b940409d76d6cd1e21e4f0","IPY_MODEL_dff388de0d854686b2c34e0c0c7eb30d"],"layout":"IPY_MODEL_470acba43fc24a25816e067cf0dcb1ff"}},"ce669861c7864894a944eed1bcc99e30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52bd279bdccc4aeb9aec7a82fa258b2e","placeholder":"​","style":"IPY_MODEL_783b21471068446c9039a391d443bf80","value":"Downloading: 100%"}},"34fec00797b940409d76d6cd1e21e4f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_778342c94cf3429d99a56d6951f9d317","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_22bcce4caa7f45658c9ddb24828e8b70","value":625}},"dff388de0d854686b2c34e0c0c7eb30d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b04a28a659ef41fbbffc77d00c86ce48","placeholder":"​","style":"IPY_MODEL_613c1a3e513141e89d2116d00d36c7c2","value":" 625/625 [00:00&lt;00:00, 19.3kB/s]"}},"470acba43fc24a25816e067cf0dcb1ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52bd279bdccc4aeb9aec7a82fa258b2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"783b21471068446c9039a391d443bf80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"778342c94cf3429d99a56d6951f9d317":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22bcce4caa7f45658c9ddb24828e8b70":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b04a28a659ef41fbbffc77d00c86ce48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"613c1a3e513141e89d2116d00d36c7c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XiPyGd6x-Cmx","executionInfo":{"status":"ok","timestamp":1663943212340,"user_tz":-420,"elapsed":10193,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"1cbd6e8d-67f3-4b1c-c92d-5e6ebd0ec8ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Gen RAM Free: 12.3 GB  | Proc size: 96.4 MB\n","GPU RAM Free: 15109MB | Used: 0MB | Util   0% | Total 15109MB\n"]}],"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil --q\n","!pip install psutil --q\n","!pip install humanize --q\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"]},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive # import drive from google colab\n","\n","ROOT = \"/content/drive/\"     # default location for the drive\n","drive.mount(ROOT)           # we mount the google drive at /content/drive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X6-Cg6_8J4L9","executionInfo":{"status":"ok","timestamp":1663943810398,"user_tz":-420,"elapsed":598066,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"10c3fb3d-4a2d-4e16-dfa3-7c8825f7821a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["import torch\n","\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AkGOtDoqKPyf","executionInfo":{"status":"ok","timestamp":1663943812316,"user_tz":-420,"elapsed":1922,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"12544b9f-20e8-41b5-a0e6-529c3b64eeb9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["!pip install transformers --q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBC15FXUKaEx","executionInfo":{"status":"ok","timestamp":1663943828280,"user_tz":-420,"elapsed":15968,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"0c446e13-4327-4358-cac2-4839f3de744b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.9 MB 7.9 MB/s \n","\u001b[K     |████████████████████████████████| 120 kB 65.4 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 45.0 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","train = pd.read_csv(\"train.csv\", usecols=[\"text_a\", \"label\"])\n","test = pd.read_csv(\"test.csv\")\n","print(train)\n","print(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Zq27y1HLSIK","executionInfo":{"status":"ok","timestamp":1663943902332,"user_tz":-420,"elapsed":359,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"589e269a-76ab-436a-d776-b33e87d867ab"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  text_a label\n","0      betewe buka twitter cuman ngetweet liat home b...    no\n","1      mas piyuuu mugo2 corona tuh mulut tersumpal ma...    no\n","2      e100ss gini buka informasi sejelas nya identit...   yes\n","3      neng solo wes ono terduga corona cobo neng ati...    no\n","4      midiahn nii akun gak takut takut nya isu coron...    no\n","...                                                  ...   ...\n","21596  depok panas ga karuan kereta sampe pasming huj...    no\n","21597  oxfara arie kriting yg lebi goblo nya orang ke...    no\n","21598  virus corona menyaba depok cuci tangan makan n...    no\n","21599  mata sipit tinggal depok udah abis dah bahan c...    no\n","21600       i ak batuk pilek pusing demam anjir ak depok    no\n","\n","[21601 rows x 2 columns]\n","                                                 text_a label\n","0                               jek dajal ga depok bang    no\n","1     detikcom untung depok masuk wilayah nya ridwan...    no\n","2     df dom jakarta depok yg gunain vc cabang nya c...    no\n","3                                     your2rl depok jkt    no\n","4     doakan indonesia selamat virus corona pkb depo...   yes\n","...                                                 ...   ...\n","2795  ku tenang2 bae ku sih ya corona nya ga depok k...    no\n","2796  guru hati hati ya virus corona uda indonesia t...   yes\n","2797  4 terawan menyebut virus corona indonesia terd...   yes\n","2798        realffk buhari can t pronounce corona virus    no\n","2799  hadapi wabah corona pemuda muhammadiyah pemeri...   yes\n","\n","[2800 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["from sklearn import preprocessing\n","\n","# dict mapping\n","labels = [\"no\", \"yes\"]\n","le = preprocessing.LabelEncoder()\n","le.fit(labels)\n","\n","train[\"label\"] = le.transform(train[\"label\"])\n","test[\"label\"] = le.transform(test[\"label\"])\n","print(train)\n","print(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IoZyYIorLMnJ","executionInfo":{"status":"ok","timestamp":1663943903696,"user_tz":-420,"elapsed":1022,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"24d88804-4f85-4e5c-9d44-8e73334714b2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  text_a  label\n","0      betewe buka twitter cuman ngetweet liat home b...      0\n","1      mas piyuuu mugo2 corona tuh mulut tersumpal ma...      0\n","2      e100ss gini buka informasi sejelas nya identit...      1\n","3      neng solo wes ono terduga corona cobo neng ati...      0\n","4      midiahn nii akun gak takut takut nya isu coron...      0\n","...                                                  ...    ...\n","21596  depok panas ga karuan kereta sampe pasming huj...      0\n","21597  oxfara arie kriting yg lebi goblo nya orang ke...      0\n","21598  virus corona menyaba depok cuci tangan makan n...      0\n","21599  mata sipit tinggal depok udah abis dah bahan c...      0\n","21600       i ak batuk pilek pusing demam anjir ak depok      0\n","\n","[21601 rows x 2 columns]\n","                                                 text_a  label\n","0                               jek dajal ga depok bang      0\n","1     detikcom untung depok masuk wilayah nya ridwan...      0\n","2     df dom jakarta depok yg gunain vc cabang nya c...      0\n","3                                     your2rl depok jkt      0\n","4     doakan indonesia selamat virus corona pkb depo...      1\n","...                                                 ...    ...\n","2795  ku tenang2 bae ku sih ya corona nya ga depok k...      0\n","2796  guru hati hati ya virus corona uda indonesia t...      1\n","2797  4 terawan menyebut virus corona indonesia terd...      1\n","2798        realffk buhari can t pronounce corona virus      0\n","2799  hadapi wabah corona pemuda muhammadiyah pemeri...      1\n","\n","[2800 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","import nltk\n","import collections\n","nltk.download('punkt')\n","\n","def get_frequent_word(df):\n","    text = \" \".join(list(df['text_a'].str.lower()))\n","    word_list = word_tokenize(text)\n","    word_count = dict(collections.Counter(word_list))\n","    d_word_freq = pd.DataFrame(data = {'word': list(word_count.keys()), 'freq': list(word_count.values())})\n","    \n","    return d_word_freq\n","\n","def cleansing(text, stopword = None):\n","    word_list = word_tokenize(text.lower())\n","    word_list = [word for word in word_list if len(word) > 2]\n","    word_list = [word for word in word_list if word.isalnum()]\n","    if stopword == None:\n","        text = ' '.join(word_list)\n","    else:\n","        word_list = [word for word in word_list if word not in stopword]\n","        text = ' '.join(word_list)\n","                \n","    return text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRRgAaGGNaEY","executionInfo":{"status":"ok","timestamp":1663943905060,"user_tz":-420,"elapsed":1367,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"639280db-83db-435e-c755-c984838e73f8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["d_w_f = get_frequent_word(train)\n","# Check alphanumeric\n","d_w_f['is_alnum'] = d_w_f.word.str.isalnum()\n","# select only alphanumeric word (ignore punctuation)\n","d_w_f_selected = d_w_f[d_w_f['is_alnum'] == True].sort_values(by = 'freq', ascending = False)\n","print(d_w_f_selected.head(15))\n","print(d_w_f_selected.tail(15))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89GSJdsHPppI","executionInfo":{"status":"ok","timestamp":1663943907169,"user_tz":-420,"elapsed":2112,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"4e8402dc-ab91-4e46-cf3e-623f68d9790d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["            word  freq  is_alnum\n","8         corona  8172      True\n","36           nya  4813      True\n","588            t  4371      True\n","587        https  4347      True\n","589           co  4314      True\n","13            yg  4011      True\n","238        covid  2768      True\n","171        virus  2662      True\n","239           19  2622      True\n","677        depok  2068      True\n","3341        psbb  1987      True\n","146           ya  1873      True\n","3708  distancing  1760      True\n","118           ga  1537      True\n","15           aja  1508      True\n","                 word  freq  is_alnum\n","15843      nlmz7ib4od     1      True\n","29082           loker     1      True\n","29081     audyaulidya     1      True\n","29078              gc     1      True\n","15848      ulangtahun     1      True\n","29077       ngerandom     1      True\n","15846      sejenisnya     1      True\n","29075       sometimes     1      True\n","29074            ixyg     1      True\n","29073           picik     1      True\n","15847  omyangbaikhati     1      True\n","29071         ketatin     1      True\n","29070       nyarankan     1      True\n","29069        10418883     1      True\n","23519      adgfocxm3q     1      True\n"]}]},{"cell_type":"code","source":["# Create stopwords list\n","stopwords = list(d_w_f_selected[(d_w_f_selected['freq'].between(4000, 5000)) | (d_w_f_selected['freq'] < 2)].word)\n","custom_stopwords = ['ya', 'aja', 'yg', 'sih', 'ga', 'gak','gy']\n","stopwords = stopwords + custom_stopwords\n","print(stopwords[:50])\n","print(\"stopwords count: {}\".format(len(stopwords)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1HMmDk4Q0br","executionInfo":{"status":"ok","timestamp":1663952119055,"user_tz":-420,"elapsed":3,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"34278f34-e4ea-4f22-a783-8d36704d4a2f"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["['nya', 't', 'https', 'co', 'yg', 'angele', 'gakepikiran', 'tarap', 'jannotama', 'titah', 'perantara', 'ck', 'dimirip2kn', 'siamini', 'maranatha', 'sbln', 'yudiistiono09', 'tabliki', 'gambarx', 'delok2', 'ngalahkan', 'hndak', 'immaranatha', 'r2bvpvizoc', 'vrpelelxyx', 'ypdg', 'direken', 'sistemik', 'sambal', 'zzasqia', 'memamg', 'sebarannya', 'ciao', 'mop', 'scanerio', 'viruspun', 'fadliyzon', 'brsma', 'maxiswecare', 'kkrytqxcyk', 'kegagaln', '7xk2fkwel2', 'kebijakanpemimpindiktator', 'ckck', 'jamat', 'nyari2', 'budiadiputro', 'undisclosedonny', 'kuk', 'tikar']\n","stopwords count: 23575\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","for i in tqdm(range(len(train))):\n","    train.loc[i, 'text_cleansing'] = cleansing(train.loc[i, 'text_a'], stopword=stopwords)\n","\n","for i in tqdm(range(len(test))):\n","    test.loc[i, 'text_cleansing'] = cleansing(test.loc[i, 'text_a'], stopword=stopwords)\n","\n","print(train)\n","print(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVZkfe-VQ7SK","executionInfo":{"status":"ok","timestamp":1663944094742,"user_tz":-420,"elapsed":187578,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"3ee4c2cf-96af-4e35-996f-55b4e4506772"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 21601/21601 [02:48<00:00, 128.44it/s]\n","100%|██████████| 2800/2800 [00:19<00:00, 145.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                                                  text_a  label  \\\n","0      betewe buka twitter cuman ngetweet liat home b...      0   \n","1      mas piyuuu mugo2 corona tuh mulut tersumpal ma...      0   \n","2      e100ss gini buka informasi sejelas nya identit...      1   \n","3      neng solo wes ono terduga corona cobo neng ati...      0   \n","4      midiahn nii akun gak takut takut nya isu coron...      0   \n","...                                                  ...    ...   \n","21596  depok panas ga karuan kereta sampe pasming huj...      0   \n","21597  oxfara arie kriting yg lebi goblo nya orang ke...      0   \n","21598  virus corona menyaba depok cuci tangan makan n...      0   \n","21599  mata sipit tinggal depok udah abis dah bahan c...      0   \n","21600       i ak batuk pilek pusing demam anjir ak depok      0   \n","\n","                                          text_cleansing  \n","0      betewe buka twitter cuman ngetweet liat home b...  \n","1      mas piyuuu mugo2 corona tuh mulut tersumpal co...  \n","2      e100ss gini buka informasi sejelas identitas d...  \n","3      neng solo wes ono terduga corona cobo neng ati...  \n","4        midiahn nii akun takut takut isu corona wkwkwkw  \n","...                                                  ...  \n","21596  depok panas karuan kereta sampe pasming hujan ...  \n","21597  oxfara arie kriting lebi goblo orang kebanyaka...  \n","21598  virus corona menyaba depok cuci tangan makan b...  \n","21599  mata sipit tinggal depok udah abis dah bahan c...  \n","21600               batuk pilek pusing demam anjir depok  \n","\n","[21601 rows x 3 columns]\n","                                                 text_a  label  \\\n","0                               jek dajal ga depok bang      0   \n","1     detikcom untung depok masuk wilayah nya ridwan...      0   \n","2     df dom jakarta depok yg gunain vc cabang nya c...      0   \n","3                                     your2rl depok jkt      0   \n","4     doakan indonesia selamat virus corona pkb depo...      1   \n","...                                                 ...    ...   \n","2795  ku tenang2 bae ku sih ya corona nya ga depok k...      0   \n","2796  guru hati hati ya virus corona uda indonesia t...      1   \n","2797  4 terawan menyebut virus corona indonesia terd...      1   \n","2798        realffk buhari can t pronounce corona virus      0   \n","2799  hadapi wabah corona pemuda muhammadiyah pemeri...      1   \n","\n","                                         text_cleansing  \n","0                                  jek dajal depok bang  \n","1     detikcom untung depok masuk wilayah ridwan kam...  \n","2     dom jakarta depok gunain cabang cabang pas kes...  \n","3                                     your2rl depok jkt  \n","4     doakan indonesia selamat virus corona pkb depo...  \n","...                                                 ...  \n","2795                             bae corona depok salah  \n","2796  guru hati hati virus corona uda indonesia teme...  \n","2797  terawan menyebut virus corona indonesia terdet...  \n","2798          realffk buhari can pronounce corona virus  \n","2799  hadapi wabah corona pemuda muhammadiyah pemeri...  \n","\n","[2800 rows x 3 columns]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["71673315a4b749149fe537b05e0a8839","175cad295c484795aad2e0a6a5906ef3","47fcf7dec6734c2bb3aea6df85aad94b","a249d2100f5947adab4279ef94e28484","3f8cc1ead55f4485b8be2655477a53c4","f6f5d4e745b34a658886574f362e7fb2","d0d5c34fdd6345069401590a4bea0d82","74b1e23c6e374798bf64aaeb68fc0980","e6a0bd9eba7e4b7589f31888c67f8eb7","c0f76e1e1778461cb2e19b39a62da2fd","317d619f824a4408ba1bf0fa8914639f","b8d1788d398042ea9e9e9c83341f263d","db7471052cbd42d3b056a02274f2ff39","5023b1054cd7422e9ed0f46b21df8832","abf241d1e42a4a6ca16a4abec11de695","4f2c7d5c6fcf42cd9762cac96d1ac088","d277e49a84674c5ab627f77048171a6c","1b0a988422ed4bcf82b25861f6a5911b","ffc38f6570434896bc06e2dbc5ed4fa7","3273a302face491dba88152561c1f080","91e101f1a40d48fd9914b8168f97f85e","b21d663a82e74a7492fd444911f7554f","2c1555562b7e4f7ea2dff9ebe39950a9","8e7d5fb14f7f472b9cdf8f44fc614b92","786a87661882429f847da3b53c4e9f89","2a695cefd0e44a71b3bed2ecb51caf20","8ac8e873d1224b27ab6d45cb0965a593","68a542ae389441f19c9ab1343cde6c4d","ed79622d30b440aa9df6f8acca2e303f","e8f04f1894604124aa855ecee2403604","6ed7d2a331d44fb2a73934e76a90c5c1","e2714361b6e34d9f99973a545a22c116","ece7a32729e444528b4be7046ceec901","e7baf9992cd64b92b0e210ef949139fa","ce669861c7864894a944eed1bcc99e30","34fec00797b940409d76d6cd1e21e4f0","dff388de0d854686b2c34e0c0c7eb30d","470acba43fc24a25816e067cf0dcb1ff","52bd279bdccc4aeb9aec7a82fa258b2e","783b21471068446c9039a391d443bf80","778342c94cf3429d99a56d6951f9d317","22bcce4caa7f45658c9ddb24828e8b70","b04a28a659ef41fbbffc77d00c86ce48","613c1a3e513141e89d2116d00d36c7c2"]},"id":"GGc9iIlNVXpw","executionInfo":{"status":"ok","timestamp":1663944097800,"user_tz":-420,"elapsed":3106,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"24d2b0e9-89ea-480c-affe-53016df7a694"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71673315a4b749149fe537b05e0a8839"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8d1788d398042ea9e9e9c83341f263d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1555562b7e4f7ea2dff9ebe39950a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7baf9992cd64b92b0e210ef949139fa"}},"metadata":{}}]},{"cell_type":"code","source":["import statistics\n","sent_length = []\n","\n","# For every sentence...\n","for sentence in train[\"text_cleansing\"]:\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n","    sent_length.append(len(input_ids))\n","\n","print('Average length = ', sum(sent_length)/len(sent_length))\n","print('Median length = ', statistics.median(sent_length))\n","print('Max length = ', max(sent_length))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50lzDjrfaFSO","executionInfo":{"status":"ok","timestamp":1663944106732,"user_tz":-420,"elapsed":8938,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"58503ba5-176a-451e-d599-8987b72c8f83"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["Average length =  26.888801444377574\n","Median length =  23\n","Max length =  1003\n"]}]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to their word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in train[\"text_cleansing\"]:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 256,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(train[\"label\"])\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', train[\"text_cleansing\"][0])\n","print('Token IDs:', input_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywGF1TQka893","executionInfo":{"status":"ok","timestamp":1663944119897,"user_tz":-420,"elapsed":13179,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"8bbf5f5e-ae1d-4b58-836a-a848dbbcea14"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:  betewe buka twitter cuman ngetweet liat home berita corona panik kepikiran ndamau buka2 home aware stay home nda rumah kalo nda penting2 banget\n","Token IDs: tensor([  101, 13009, 26127, 10112, 11499, 10371,   188, 56082, 10877, 16008,\n","        10206, 10743, 10308, 12577, 10308, 11614, 10526, 11816, 84836, 31206,\n","        97586, 10174, 11163, 70583, 27974, 24477, 89793, 11499, 10371, 10729,\n","        11816, 66625, 29597, 11816, 24477, 22740, 10730, 10715, 24477, 34162,\n","        10729, 17937, 10308,   102,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0])\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 80-20 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('training samples count: {}'.format(train_size))\n","print('validation samples count: {}'.format(val_size))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfdhWFFkcCRq","executionInfo":{"status":"ok","timestamp":1663944119898,"user_tz":-420,"elapsed":20,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"aaa9a19f-1a72-4b73-8eb0-7fb450cdefbd"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["training samples count: 17280\n","validation samples count: 4321\n"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"metadata":{"id":"dORtqvMqcrjo","executionInfo":{"status":"ok","timestamp":1663944119899,"user_tz":-420,"elapsed":12,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    'bert-base-multilingual-cased', # Use the 12-layer BERT model, with an cased vocab.\n","    num_labels = 2, \n","    output_attentions = False, # return attentions weights\n","    output_hidden_states = False, # returns all hidden-states\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NU1sKyClu_Lx","executionInfo":{"status":"ok","timestamp":1663945631883,"user_tz":-420,"elapsed":3851,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"020d2b86-ff45-495e-c5d6-2e38dba79e49"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uRV521nsvFuK","executionInfo":{"status":"ok","timestamp":1663945631884,"user_tz":-420,"elapsed":23,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"1724103e-4d77-4070-cd28-c00bae549877"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (119547, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"]}]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, \n","                  eps = 1e-8\n","                )\n","\n","epochs = 3\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","print('Jumlah batch :', len(train_dataloader))\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nnYIzo1lzNft","executionInfo":{"status":"ok","timestamp":1663945631884,"user_tz":-420,"elapsed":15,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"b78c87f3-69a1-4fe9-ce46-61207f64a0dd"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Jumlah batch : 540\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"p4fi5GJ1z6aH","executionInfo":{"status":"ok","timestamp":1663945631884,"user_tz":-420,"elapsed":12,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"Mtb0Wi9Hz8-W","executionInfo":{"status":"ok","timestamp":1663945631885,"user_tz":-420,"elapsed":13,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# List variable for store training and validation loss, validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 20 batches.\n","        if step % 20 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a backward pass\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # token_type_ids is same as the \"segment ids\", which differentiates \n","        # sentence 1 and 2 in sentence-pair tasks\n","        b_model = model(b_input_ids, \n","                             token_type_ids=None,\n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        loss = b_model.loss\n","        logits = b_model.logits\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. \n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode (batchnorm, dropout disable)\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Deactivate autograd, it will reduce memory usage and speed up computations\n","        # but you won’t be able to backprop (which you don’t want in an eval script).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            b_model = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        loss = b_model.loss\n","        logits = b_model.logits\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'Epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Validation Loss': avg_val_loss,\n","            'Validation Accuracy': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVZu2_z60Cfg","executionInfo":{"status":"ok","timestamp":1663948895077,"user_tz":-420,"elapsed":2357560,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"536277a8-fa74-4220-839e-83d2b8b54618"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 3 ========\n","Training...\n","  Batch    20  of    540.    Elapsed: 0:00:25.\n","  Batch    40  of    540.    Elapsed: 0:00:50.\n","  Batch    60  of    540.    Elapsed: 0:01:16.\n","  Batch    80  of    540.    Elapsed: 0:01:42.\n","  Batch   100  of    540.    Elapsed: 0:02:08.\n","  Batch   120  of    540.    Elapsed: 0:02:34.\n","  Batch   140  of    540.    Elapsed: 0:03:01.\n","  Batch   160  of    540.    Elapsed: 0:03:27.\n","  Batch   180  of    540.    Elapsed: 0:03:54.\n","  Batch   200  of    540.    Elapsed: 0:04:21.\n","  Batch   220  of    540.    Elapsed: 0:04:48.\n","  Batch   240  of    540.    Elapsed: 0:05:14.\n","  Batch   260  of    540.    Elapsed: 0:05:41.\n","  Batch   280  of    540.    Elapsed: 0:06:08.\n","  Batch   300  of    540.    Elapsed: 0:06:35.\n","  Batch   320  of    540.    Elapsed: 0:07:01.\n","  Batch   340  of    540.    Elapsed: 0:07:28.\n","  Batch   360  of    540.    Elapsed: 0:07:55.\n","  Batch   380  of    540.    Elapsed: 0:08:22.\n","  Batch   400  of    540.    Elapsed: 0:08:48.\n","  Batch   420  of    540.    Elapsed: 0:09:15.\n","  Batch   440  of    540.    Elapsed: 0:09:42.\n","  Batch   460  of    540.    Elapsed: 0:10:08.\n","  Batch   480  of    540.    Elapsed: 0:10:35.\n","  Batch   500  of    540.    Elapsed: 0:11:02.\n","  Batch   520  of    540.    Elapsed: 0:11:29.\n","\n","  Average training loss: 0.31\n","  Training epoch took: 0:11:55\n","\n","Running Validation...\n","  Accuracy: 0.87\n","  Validation Loss: 0.32\n","  Validation took: 0:01:07\n","\n","======== Epoch 2 / 3 ========\n","Training...\n","  Batch    20  of    540.    Elapsed: 0:00:27.\n","  Batch    40  of    540.    Elapsed: 0:00:54.\n","  Batch    60  of    540.    Elapsed: 0:01:20.\n","  Batch    80  of    540.    Elapsed: 0:01:47.\n","  Batch   100  of    540.    Elapsed: 0:02:14.\n","  Batch   120  of    540.    Elapsed: 0:02:40.\n","  Batch   140  of    540.    Elapsed: 0:03:07.\n","  Batch   160  of    540.    Elapsed: 0:03:34.\n","  Batch   180  of    540.    Elapsed: 0:04:01.\n","  Batch   200  of    540.    Elapsed: 0:04:27.\n","  Batch   220  of    540.    Elapsed: 0:04:54.\n","  Batch   240  of    540.    Elapsed: 0:05:21.\n","  Batch   260  of    540.    Elapsed: 0:05:47.\n","  Batch   280  of    540.    Elapsed: 0:06:14.\n","  Batch   300  of    540.    Elapsed: 0:06:41.\n","  Batch   320  of    540.    Elapsed: 0:07:07.\n","  Batch   340  of    540.    Elapsed: 0:07:34.\n","  Batch   360  of    540.    Elapsed: 0:08:01.\n","  Batch   380  of    540.    Elapsed: 0:08:28.\n","  Batch   400  of    540.    Elapsed: 0:08:54.\n","  Batch   420  of    540.    Elapsed: 0:09:21.\n","  Batch   440  of    540.    Elapsed: 0:09:48.\n","  Batch   460  of    540.    Elapsed: 0:10:15.\n","  Batch   480  of    540.    Elapsed: 0:10:41.\n","  Batch   500  of    540.    Elapsed: 0:11:08.\n","  Batch   520  of    540.    Elapsed: 0:11:35.\n","\n","  Average training loss: 0.24\n","  Training epoch took: 0:12:01\n","\n","Running Validation...\n","  Accuracy: 0.88\n","  Validation Loss: 0.34\n","  Validation took: 0:01:06\n","\n","======== Epoch 3 / 3 ========\n","Training...\n","  Batch    20  of    540.    Elapsed: 0:00:27.\n","  Batch    40  of    540.    Elapsed: 0:00:53.\n","  Batch    60  of    540.    Elapsed: 0:01:20.\n","  Batch    80  of    540.    Elapsed: 0:01:47.\n","  Batch   100  of    540.    Elapsed: 0:02:14.\n","  Batch   120  of    540.    Elapsed: 0:02:40.\n","  Batch   140  of    540.    Elapsed: 0:03:07.\n","  Batch   160  of    540.    Elapsed: 0:03:34.\n","  Batch   180  of    540.    Elapsed: 0:04:00.\n","  Batch   200  of    540.    Elapsed: 0:04:27.\n","  Batch   220  of    540.    Elapsed: 0:04:54.\n","  Batch   240  of    540.    Elapsed: 0:05:20.\n","  Batch   260  of    540.    Elapsed: 0:05:47.\n","  Batch   280  of    540.    Elapsed: 0:06:14.\n","  Batch   300  of    540.    Elapsed: 0:06:41.\n","  Batch   320  of    540.    Elapsed: 0:07:07.\n","  Batch   340  of    540.    Elapsed: 0:07:34.\n","  Batch   360  of    540.    Elapsed: 0:08:01.\n","  Batch   380  of    540.    Elapsed: 0:08:28.\n","  Batch   400  of    540.    Elapsed: 0:08:54.\n","  Batch   420  of    540.    Elapsed: 0:09:21.\n","  Batch   440  of    540.    Elapsed: 0:09:48.\n","  Batch   460  of    540.    Elapsed: 0:10:14.\n","  Batch   480  of    540.    Elapsed: 0:10:41.\n","  Batch   500  of    540.    Elapsed: 0:11:08.\n","  Batch   520  of    540.    Elapsed: 0:11:34.\n","\n","  Average training loss: 0.21\n","  Training epoch took: 0:12:01\n","\n","Running Validation...\n","  Accuracy: 0.88\n","  Validation Loss: 0.34\n","  Validation took: 0:01:06\n","\n","Training complete!\n","Total training took 0:39:17 (h:mm:ss)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('Epoch')\n","\n","# Display the table.\n","df_stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"eGBxsCbk0EKq","executionInfo":{"status":"ok","timestamp":1663948931997,"user_tz":-420,"elapsed":393,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"947eb4b2-e150-4e28-8548-e27f79b44947"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Training Loss  Validation Loss  Validation Accuracy Training Time  \\\n","Epoch                                                                      \n","1               0.31             0.32                 0.87       0:11:55   \n","2               0.24             0.34                 0.88       0:12:01   \n","3               0.21             0.34                 0.88       0:12:01   \n","\n","      Validation Time  \n","Epoch                  \n","1             0:01:07  \n","2             0:01:06  \n","3             0:01:06  "],"text/html":["\n","  <div id=\"df-f3548ba8-2fd2-42f9-9c57-c895b6382b38\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Validation Accuracy</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>Epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.31</td>\n","      <td>0.32</td>\n","      <td>0.87</td>\n","      <td>0:11:55</td>\n","      <td>0:01:07</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.24</td>\n","      <td>0.34</td>\n","      <td>0.88</td>\n","      <td>0:12:01</td>\n","      <td>0:01:06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.21</td>\n","      <td>0.34</td>\n","      <td>0.88</td>\n","      <td>0:12:01</td>\n","      <td>0:01:06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3548ba8-2fd2-42f9-9c57-c895b6382b38')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f3548ba8-2fd2-42f9-9c57-c895b6382b38 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f3548ba8-2fd2-42f9-9c57-c895b6382b38');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","test_sentences = test[\"text_cleansing\"]\n","test_labels = test[\"label\"]\n","\n","# For every sentence...\n","for sent in test_sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 256,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(test_labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2JxuEfGrFr_Y","executionInfo":{"status":"ok","timestamp":1663951085265,"user_tz":-420,"elapsed":2044,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"7afe52e8-98e1-4e68-c8cf-64e1178418c9"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('    DONE.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nE0-iAtEGFSc","executionInfo":{"status":"ok","timestamp":1663952835895,"user_tz":-420,"elapsed":38221,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"cf039b77-f840-4264-93e6-4d3c11d6067a"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 2,800 test sentences...\n","    DONE.\n"]}]},{"cell_type":"code","source":["# Calculate accuracy for test dataset\n","total_accuracy = 0\n","for batch_num in range(len(predictions)): \n","  total_accuracy += flat_accuracy(predictions[batch_num], true_labels[batch_num])\n","\n","total_accuracy = total_accuracy/len(predictions)\n","print('Accuracy on test dataset: {}'.format(total_accuracy))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-PcVXlOGYx3","executionInfo":{"status":"ok","timestamp":1663952843985,"user_tz":-420,"elapsed":3,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"a34d1c73-3736-458c-c11c-6c669ab85953"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test dataset: 0.8490767045454546\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = 'drive/My Drive/DSI/model/'\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HckYKfqaGbFC","executionInfo":{"status":"ok","timestamp":1663949424784,"user_tz":-420,"elapsed":3143,"user":{"displayName":"13519123 Muhammad Rifky Muthahhari","userId":"11015367298495493707"}},"outputId":"07183d27-180e-4fca-940f-b8045deb81de"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to drive/My Drive/DSI/model/\n"]},{"output_type":"execute_result","data":{"text/plain":["('drive/My Drive/DSI/model/tokenizer_config.json',\n"," 'drive/My Drive/DSI/model/special_tokens_map.json',\n"," 'drive/My Drive/DSI/model/vocab.txt',\n"," 'drive/My Drive/DSI/model/added_tokens.json')"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# Load a trained model and vocabulary that you have fine-tuned\n","model = BertForSequenceClassification.from_pretrained(output_dir)\n","tokenizer = BertTokenizer.from_pretrained(output_dir)\n","\n","# Copy the model to the GPU.\n","model.to(device)"],"metadata":{"id":"ZsgWO3EuHPxw"},"execution_count":null,"outputs":[]}]}