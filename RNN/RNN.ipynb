{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mepLRHZEkycv",
        "outputId": "dd430105-1a6f-4b4a-ba72-09823b518b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install --user gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U numpy==1.18.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RxnQmEFicqF",
        "outputId": "d1b345fe-d09c-4da1-a474-a7a1220c6c14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (1.18.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# gensim\n",
        "from gensim.models import FastText\n",
        "\n",
        "# keras\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "KDng5_4Fzh4p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"../dataset/train.csv\")\n",
        "dev_df = pd.read_csv(\"../dataset/dev.csv\")\n",
        "test_df = pd.read_csv(\"../dataset/test.csv\")\n",
        "\n",
        "train_seqs = [_ for _ in train_df[\"text_a\"]]\n",
        "train_labels = np.array([1 if (label == \"yes\") else 0 for label in train_df[\"label\"]])\n",
        "\n",
        "dev_seqs = [_ for _ in dev_df[\"text_a\"]]\n",
        "dev_labels = np.array([1 if (label == \"yes\") else 0 for label in dev_df[\"label\"]])\n",
        "\n",
        "test_seqs = [_ for _ in test_df[\"text_a\"]]\n",
        "test_labels = np.array([1 if (label == \"yes\") else 0 for label in test_df[\"label\"]])\n",
        "\n",
        "for i, seq in enumerate(train_seqs):\n",
        "  train_seqs[i] = seq.split(\" \")\n",
        "\n",
        "for i, seq in enumerate(dev_seqs):\n",
        "  dev_seqs[i] = seq.split(\" \")\n",
        "\n",
        "for i, seq in enumerate(test_seqs):\n",
        "  test_seqs[i] = seq.split(\" \")"
      ],
      "metadata": {
        "id": "42W43xU4keJf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data\n",
        "\n",
        "vocab = []\n",
        "  \n",
        "for seq in train_seqs:\n",
        "  for token in seq:\n",
        "    if token not in vocab:\n",
        "      vocab.append(token)\n",
        "\n",
        "for seq in dev_seqs:\n",
        "  for token in seq:\n",
        "    if token not in vocab:\n",
        "      vocab.append(token)\n",
        "\n",
        "for seq in test_seqs:\n",
        "  for token in seq:\n",
        "    if token not in vocab:\n",
        "      vocab.append(token)\n",
        "\n",
        "def vocab_generator(vocab):\n",
        "  yield vocab"
      ],
      "metadata": {
        "id": "kidJk55rk75q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model on vocab\n",
        "vec_model = FastText(size = 100, min_count = 1, window = 5)\n",
        "vec_model.build_vocab(vocab_generator(vocab))\n",
        "vec_model.train(vocab_generator(vocab), total_examples=vec_model.corpus_count, epochs=vec_model.iter)\n",
        "\n",
        "train_data = [vec_model[seq] for seq in train_seqs]\n",
        "dev_data = [vec_model[seq] for seq in dev_seqs]\n",
        "test_data = [vec_model[seq] for seq in test_seqs]"
      ],
      "metadata": {
        "id": "DDMrTeiVBpdP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padAndScaleData(seqs, target_size, vector_dim):\n",
        "  new_list = np.zeros((len(seqs), target_size, vector_dim))\n",
        "  \n",
        "  for i, seq in enumerate(seqs):\n",
        "    for j in range(min(target_size, len(seq))):\n",
        "      new_list[i][j] = 1000*seq[j]\n",
        "\n",
        "  return new_list\n",
        "\n",
        "max_seq_length = 124\n",
        "\n",
        "train_data_padded = padAndScaleData(train_data, max_seq_length, 100)\n",
        "dev_data_padded = padAndScaleData(dev_data, max_seq_length, 100)\n",
        "test_data_padded = padAndScaleData(test_data, max_seq_length, 100)\n",
        "\n",
        "train_data_padded = train_data_padded.reshape(len(train_labels), max_seq_length, 100)\n",
        "dev_data_padded = dev_data_padded.reshape(len(dev_labels), max_seq_length, 100)\n",
        "test_data_padded = test_data_padded.reshape(len(test_labels), max_seq_length, 100)"
      ],
      "metadata": {
        "id": "xXTo9kEBFwNz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rnn with vectors as inputs\n",
        "dl_model = tf.keras.Sequential()\n",
        "# dl_model.add(layers.Embedding(input_dim=100, output_dim=64, mask_zero=True))\n",
        "dl_model.add(tf.keras.layers.LSTM(128, input_shape=(max_seq_length, 100)))\n",
        "dl_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "dl_model.add(tf.keras.layers.Dense(32, activation='sigmoid'))\n",
        "dl_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "dl_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])\n",
        "history = dl_model.fit(x=train_data_padded, y=train_labels, epochs=10, validation_data=(dev_data_padded, dev_labels), validation_steps=10)\n",
        "\n",
        "# validate results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvlTr9nB44r_",
        "outputId": "88e701d0-a338-47ea-8561-14973dc16c27"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 21601 samples, validate on 2800 samples\n",
            "Epoch 1/10\n",
            "21601/21601 [==============================] - 92s 4ms/sample - loss: 0.7222 - accuracy: 0.6791 - val_loss: 0.0804 - val_accuracy: 0.8469\n",
            "Epoch 2/10\n",
            "21601/21601 [==============================] - 88s 4ms/sample - loss: 0.6981 - accuracy: 0.7189 - val_loss: 0.0800 - val_accuracy: 0.8469\n",
            "Epoch 3/10\n",
            "21601/21601 [==============================] - 91s 4ms/sample - loss: 0.6963 - accuracy: 0.7187 - val_loss: 0.0797 - val_accuracy: 0.8469\n",
            "Epoch 4/10\n",
            "21601/21601 [==============================] - 91s 4ms/sample - loss: 0.6952 - accuracy: 0.7183 - val_loss: 0.0796 - val_accuracy: 0.8469\n",
            "Epoch 5/10\n",
            "21601/21601 [==============================] - 91s 4ms/sample - loss: 0.6945 - accuracy: 0.7185 - val_loss: 0.0795 - val_accuracy: 0.8469\n",
            "Epoch 6/10\n",
            "21601/21601 [==============================] - 90s 4ms/sample - loss: 0.6940 - accuracy: 0.7186 - val_loss: 0.0794 - val_accuracy: 0.8469\n",
            "Epoch 7/10\n",
            "21601/21601 [==============================] - 91s 4ms/sample - loss: 0.6937 - accuracy: 0.7187 - val_loss: 0.0793 - val_accuracy: 0.8469\n",
            "Epoch 8/10\n",
            "21601/21601 [==============================] - 90s 4ms/sample - loss: 0.6934 - accuracy: 0.7189 - val_loss: 0.0793 - val_accuracy: 0.8469\n",
            "Epoch 9/10\n",
            "21601/21601 [==============================] - 90s 4ms/sample - loss: 0.6932 - accuracy: 0.7193 - val_loss: 0.0793 - val_accuracy: 0.8469\n",
            "Epoch 10/10\n",
            "21601/21601 [==============================] - 90s 4ms/sample - loss: 0.6932 - accuracy: 0.7191 - val_loss: 0.0793 - val_accuracy: 0.8469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = dl_model.evaluate(test_data_padded, test_labels, batch_size=128)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4-dOZo-6Q4d",
        "outputId": "a1067044-a048-42da-b944-9eaaf79fa47f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2800/2800 [==============================] - 2s 834us/sample - loss: 0.6931 - accuracy: 0.7482\n",
            "Test loss: 0.6931169853891646\n",
            "Test accuracy: 0.7482143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F6cVz7j147xr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}